{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Green loss calculation\n",
    "This material is originally developed for ACE 592 Big Data - Empirical Economics written on 8/03/2016 by Akito Kamei, Johnathan Rush, and Peter Christensen. The initial material is modifed for CyberGIS workshop.\n",
    "\n",
    "### Objective:\n",
    "* Read world map (shapefile)\n",
    "* Read green loss satellite file (tiff file)\n",
    "* Plot data\n",
    "\n",
    "### Successful outcome:\n",
    "* Calculate green loss by year\n",
    "\n",
    "#### Information\n",
    "Jupyter Notebooks autosave; check the text next to the file name at the top of the screen to see if it has saved before you close the browser tab. You can also go to the File menu and choose Save and Checkpoint, which gives you a place to revert back to if you need it.\n",
    "\n",
    "If you are done running the notebook, go to File, then Close and Halt to free up system resources for other users. This will clear out all the variables and memory, but any output from the cells you have run will still be displayed. You can run your cells again from the beginning to re-populate variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Install packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: rgdal\n",
      "Loading required package: sp\n",
      "rgdal: version: 1.1-10, (SVN revision 622)\n",
      " Geospatial Data Abstraction Library extensions to R successfully loaded\n",
      " Loaded GDAL runtime: GDAL 1.11.3, released 2015/09/16\n",
      " Path to GDAL shared files: /usr/share/gdal/1.11\n",
      " Loaded PROJ.4 runtime: Rel. 4.9.2, 08 September 2015, [PJ_VERSION: 492]\n",
      " Path to PROJ.4 shared files: (autodetected)\n",
      " Linking to sp version: 1.2-3 \n",
      "Loading required package: raster\n",
      "Loading required package: gdalUtils\n",
      "Loading required package: foreach\n",
      "Loading required package: doSNOW\n",
      "Loading required package: iterators\n",
      "Loading required package: snow\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>rgdal</dt>\n",
       "\t\t<dd>TRUE</dd>\n",
       "\t<dt>sp</dt>\n",
       "\t\t<dd>TRUE</dd>\n",
       "\t<dt>raster</dt>\n",
       "\t\t<dd>TRUE</dd>\n",
       "\t<dt>gdalUtils</dt>\n",
       "\t\t<dd>TRUE</dd>\n",
       "\t<dt>foreach</dt>\n",
       "\t\t<dd>TRUE</dd>\n",
       "\t<dt>doSNOW</dt>\n",
       "\t\t<dd>TRUE</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[rgdal] TRUE\n",
       "\\item[sp] TRUE\n",
       "\\item[raster] TRUE\n",
       "\\item[gdalUtils] TRUE\n",
       "\\item[foreach] TRUE\n",
       "\\item[doSNOW] TRUE\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "rgdal\n",
       ":   TRUEsp\n",
       ":   TRUEraster\n",
       ":   TRUEgdalUtils\n",
       ":   TRUEforeach\n",
       ":   TRUEdoSNOW\n",
       ":   TRUE\n",
       "\n"
      ],
      "text/plain": [
       "    rgdal        sp    raster gdalUtils   foreach    doSNOW \n",
       "     TRUE      TRUE      TRUE      TRUE      TRUE      TRUE "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ipak <- function(pkg){\n",
    "new.pkg <- pkg[!(pkg %in% installed.packages()[, \"Package\"])]\n",
    "if (length(new.pkg)) \n",
    "    install.packages(new.pkg, dependencies = TRUE)\n",
    "sapply(pkg, require, character.only = TRUE)\n",
    "}\n",
    "\n",
    "# usage\n",
    "packages <- c(\"rgdal\", \"sp\", \"raster\",  \"gdalUtils\", \"foreach\", \"doSNOW\")\n",
    "ipak(packages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Set the working directory to your user_work folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Change to your username\n",
    "username <- \"mhjeong\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mydir <- paste(\"/mnt/jhub/users/\", username, sep =\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "'/mnt/jhub/users/mhjeong'"
      ],
      "text/latex": [
       "'/mnt/jhub/users/mhjeong'"
      ],
      "text/markdown": [
       "'/mnt/jhub/users/mhjeong'"
      ],
      "text/plain": [
       "[1] \"/mnt/jhub/users/mhjeong\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mydir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in setwd(mydir): cannot change working directory\n",
     "output_type": "error",
     "traceback": [
      "Error in setwd(mydir): cannot change working directory\nTraceback:\n",
      "1. setwd(mydir)",
      "2. .handleSimpleError(function (e) \n . {\n .     handle_condition(e)\n .     output_handler$error(e)\n . }, \"cannot change working directory\", quote(setwd(mydir)))"
     ]
    }
   ],
   "source": [
    "setwd(mydir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "'/mnt/jhub/users/zhang303/r-training-notebooks'"
      ],
      "text/latex": [
       "'/mnt/jhub/users/zhang303/r-training-notebooks'"
      ],
      "text/markdown": [
       "'/mnt/jhub/users/zhang303/r-training-notebooks'"
      ],
      "text/plain": [
       "[1] \"/mnt/jhub/users/zhang303/r-training-notebooks\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confirm the working directory is set to what you wanted:\n",
    "getwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Load the world map polygon data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OGR data source with driver: ESRI Shapefile \n",
      "Source: \"shape\", layer: \"ne_110m_admin_0_countries\"\n",
      "with 177 features\n",
      "It has 63 fields\n"
     ]
    }
   ],
   "source": [
    "#Read world map (shapefile)\n",
    "#Set up a shape folder\n",
    "setwd(\"/mnt/jhub/\")\n",
    "# \"../../map\" is a relative path from your working directory - it means up two directories, then inside the map directory\n",
    "world=readOGR(\"shape\",layer=\"ne_110m_admin_0_countries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What does the readOGR function do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Include a question mark and then a function name to pop up a help window\n",
    "?readOGR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#You can print an object, or just enter its name to get some information about it.\n",
    "print(world)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You can also get information on a class of objects:\n",
    "?SpatialPolygonsDataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Green loss calculation\n",
    "We want to find out how much green loss there has been by country, by year. It's good to develop your approach with a small data set to start with so you can rapidly test it.\n",
    "We will use the east African country of Guinea Bissau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "world_Guinea_Bissau <- subset(world, sovereignt==\"Guinea Bissau\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "world_Guinea_Bissau@data[,\"sovereignt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change the working directory to the directory containing the loss year rasters\n",
    "setwd(\"/mnt/jhub/lossyear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Find the raster that overlays Guinea-Bissau\n",
    "# Read year of green loss satellite file (tiff file)\n",
    "lossyear_gb <- raster(\"Hansen_GFC2015_lossyear_20N_020W.tif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the metadata for the raster file we just loaded\n",
    "If you look at a map of Guinea Bissau, you'll see that the country fits entirely within the boundaries expressed by the Corner Coordinates of the raster below.\n",
    "\n",
    "`gdalinfo` needs a filename to operate on, so we are getting the `name` slot of the `file` slot of the RasterLayer object we just made. Of course, we could have given it `\"Hansen_GFC2015_lossyear_20N_020W.tif\"`, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(gdalinfo(lossyear_gb@file@name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make map of Guinea-Bissau region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We start with the raster file, which will set the extent of the map\n",
    "plot(lossyear_gb, add=FALSE)\n",
    "plot(world, border=\"red\", lwd = 2, add=TRUE)\n",
    "plot(world_Guinea_Bissau, border=\"black\", lwd = 4, add=TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Change back to your user directory to work in\n",
    "setwd(mydir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize the green cover loss year in Guinea Bissau\n",
    "Often, the approach used for this is the `extract` command in the Raster package. However, the performance of `extract` is poor, and uses an enormous amount of memory to allocate the extracted values.\n",
    "\n",
    "The method below saves computation time by first cropping the raster to the bounding box of the Guinea Bissau polygon, then to the boundaries of the actual polygon, before extracting values. Often, sending smaller input files to a function will speed up the operation, even if many of the values in a large file _should_ be ignored.\n",
    "\n",
    "The ```ext_gb``` object is a vector of every value extracted from the raster. These are then tabulated so that there is a count of every unique value. Finally, the tabulated summary is transformed into a data frame object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "time1 <- proc.time() #start timer\n",
    "startTimeGB <- time1\n",
    "clip1_gb <- crop(lossyear_gb, extent(world_Guinea_Bissau)) #crop to extent of polygon\n",
    "cat(\"crop 1:\",\"\\n\"); proc.time() - time1\n",
    "\n",
    "time1 <- proc.time() #start timer\n",
    "clip2_gb <- rasterize(world_Guinea_Bissau, clip1_gb, mask=TRUE) #crops to polygon edge & converts to raster\n",
    "cat(\"crop 2:\",\"\\n\"); proc.time() - time1\n",
    "\n",
    "time1 <- proc.time() #start timer\n",
    "ext_gb <- getValues(clip2_gb) #much faster than extract\n",
    "cat(\"getValues:\",\"\\n\"); proc.time() - time1\n",
    "\n",
    "time1 <- proc.time() #start timer\n",
    "tab_gb <-table(ext_gb) #tabulates the values of the raster in the polygon\n",
    "cat(\"tabulate:\",\"\\n\"); proc.time() - time1\n",
    "\n",
    "time1 <- proc.time() #start timer\n",
    "mat_gb <- as.data.frame(tab_gb)\n",
    "cat(\"as.data.frame(tab):\",\"\\n\"); proc.time() - time1\n",
    "\n",
    "timeGB <- proc.time() - startTimeGB\n",
    "cat(\"Total time to extract raster cell values in Guinea Bissau:\\n\")\n",
    "print(summary(timeGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Take a look at the summarized results data frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mat_gb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the summarized data frame as a bar chart\n",
    "\n",
    "##### How to make a bar plot?\n",
    "We'll check the help in the cell below. There, we've used the :: symbol to indicate which specific library's barplot function we want to use.\n",
    "\n",
    "The `raster` library overrides and extends the built-in `barplot` function from the `graphics` library. So if we just ran `?barplot`, we'd get information on using `raster`'s version. However, there is better information on the basic capabilities of the barplot function in the `graphics` library's help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Using values from position 2 on will exclude the first row - the 0 code for no loss.\n",
    "# The 0 code is much more common than any other, and would make the plot hard to read.\n",
    "GBlossyears <- mat_gb$Freq[2:length(mat_gb$Freq)]\n",
    "GBlosscodes <- mat_gb$ext_gb[2:length(mat_gb$ext_gb)]\n",
    "#Label setting\n",
    "GBlosscodes <- factor(GBlosscodes,\n",
    "levels = c(\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\",\"14\"),\n",
    "labels = c(\"2001\",\"2002\",\"2003\",\"2004\",\"2005\",\"2006\",\"2007\",\"2008\",\"2009\",\"2010\",\"2011\",\"2012\",\"2013\",\"2014\"))\n",
    "\n",
    "barplot(height = GBlossyears, names.arg = GBlosscodes, xlab = \"Code for Year of Green Loss\", beside=TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Indonesia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a copy of Indonesia's boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "world_Indonesia <- subset(world, sovereignt==\"Indonesia\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a *virtual raster* for ```lossyear``` files in for the Indonesia region\n",
    "One raster file covered the entire region of Guinea Bissau, but we will need to use several adjacent rasters to cover Indonesia.\n",
    "\n",
    "With a virtual raster file, we can reference many files as a single object. Virtual rasters have the file extension ```.vrt```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "setwd(\"/mnt/jhub/lossyear\")\n",
    "#Create a vector of file names for the Indonesia area raster files\n",
    "ind_lossyear <- c(\"/mnt/jhub/lossyear/Hansen_GFC2015_lossyear_00N_090E.tif\", \n",
    "                 \"/mnt/jhub/lossyear/Hansen_GFC2015_lossyear_00N_100E.tif\", \n",
    "                 \"/mnt/jhub/lossyear/Hansen_GFC2015_lossyear_00N_110E.tif\", \n",
    "                 \"/mnt/jhub/lossyear/Hansen_GFC2015_lossyear_00N_120E.tif\", \n",
    "                 \"/mnt/jhub/lossyear/Hansen_GFC2015_lossyear_10N_090E.tif\", \n",
    "                 \"/mnt/jhub/lossyear/Hansen_GFC2015_lossyear_10N_100E.tif\", \n",
    "                 \"/mnt/jhub/lossyear/Hansen_GFC2015_lossyear_10N_110E.tif\", \n",
    "                 \"/mnt/jhub/lossyear/Hansen_GFC2015_lossyear_10N_120E.tif\", \n",
    "                 \"/mnt/jhub/lossyear/Hansen_GFC2015_lossyear_10S_120E.tif\")\n",
    "\n",
    "# create a VRT out of the input files, store in your directory\n",
    "vrtpath <- paste(mydir, \"/indonesia.vrt\", sep=\"\")\n",
    "gdalbuildvrt(ind_lossyear, vrtpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in a virtual raster that refers to the TIFF files covering Indonesia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IndRasters <- raster(vrtpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Two ways of getting information on the rasters we've loaded:\n",
    "print(IndRasters) #print the default information for the raster object\n",
    "print(gdalinfo(IndRasters@file@name)) #print the results of gdalinfo on the filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the loss rasters with the national boundaries on top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "time1 <- proc.time() #start timer\n",
    "\n",
    "plot(IndRasters, add=FALSE)\n",
    "plot(world, border=\"red\", lwd = 1, add=TRUE)\n",
    "plot(world_Indonesia, border=\"black\", lwd = 2, add=TRUE)\n",
    "\n",
    "time2 <- proc.time() #end timer\n",
    "cat(\"Plotting time for Indonesia:\",\"\\n\")\n",
    "summary(time2 - time1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting raster values from Indonesia\n",
    "We established earlier that extracting values from Indonesia the usual way would either take too long, or use too much memory.\n",
    "\n",
    "One data parallelism strategy is called \"chunking.\" Breaking the operations into smaller chunks can let you use more processors at once, as well as better manage how much memory you use.\n",
    "\n",
    "Below, we will divide Indonesia into smaller pieces and summarize the extracted values from each one. By keeping only what we really want for each chunk - the summary of unique values - we can discard the array of every pixel value from each chunk as soon as we're done summarizing it. This will reduce the amount of memory we need to use at any one time.\n",
    "\n",
    "After chunking, we will learn how to process many of the chunks at once to speed up computation.\n",
    "\n",
    "#### How many chunks?\n",
    "There is a little overhead in terms of storage and communication for every chunk you make, so you don't want to split up the source data _too_ much. One way to estimate if we are hitting the right balance is to take a look at the plotted map after we have the chunks. Better methods include checking the number of pixels in a chunk, the memory used by the values extracted for a chunk, or the ratio of a chunk's area to the area of a region we have already calculated (like Guinea Bissau)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "time1 <- proc.time() #start timer\n",
    "\n",
    "# Get extent for country\n",
    "ind_yext <- world_Indonesia@bbox[\"y\",\"max\"] - world_Indonesia@bbox[\"y\",\"min\"]\n",
    "ind_xext <- world_Indonesia@bbox[\"x\",\"max\"] - world_Indonesia@bbox[\"x\",\"min\"]\n",
    "cat(\"Indonesia longitude extent: \", ind_xext, \"; latitude extent: \", ind_yext)\n",
    "\n",
    "# Divide lat/long extents by U/V increments to create new polygons\n",
    "# Here, we've manually chosen divisions, but you can imagine setting a maximum width for these\n",
    "udiv = 45; vdiv = 15;\n",
    "\n",
    "# Extent in map units for each rectangle\n",
    "ind_yint <- ind_yext / vdiv\n",
    "ind_xint <- ind_xext / udiv\n",
    "\n",
    "# What is the size of each rectangle?\n",
    "cat(\"\\nSubdivision rectangle width:  \", ind_xint)\n",
    "cat(\"\\nSubdivision rectangle height: \", ind_yint)\n",
    "\n",
    "#initialize an empty list with the length to hold all the grid cells we will create\n",
    "polys <- vector(\"list\", udiv*vdiv) #make a vector of type list, with a length of udiv * vdiv\n",
    "\n",
    "#loop\n",
    "for (u in 1:udiv){\n",
    "    for (v in 1:vdiv){     \n",
    "        #store the calculated extents as polygons in an indexed array\n",
    "        polys[[(u-1)*vdiv+v]] <- as(extent(world_Indonesia@bbox[\"x\",\"min\"] + ind_xint * (u-1),\n",
    "                                           world_Indonesia@bbox[\"x\",\"min\"] + ind_xint * u, \n",
    "                                           world_Indonesia@bbox[\"y\",\"min\"] + ind_yint * (v-1),\n",
    "                                           world_Indonesia@bbox[\"y\",\"min\"] + ind_yint * v),\n",
    "                                     'SpatialPolygons')\n",
    "    }\n",
    "}\n",
    "\n",
    "#merge polygons - this calls the bind function on each polygon to make them a single object\n",
    "merged_polys <- do.call(bind, polys) \n",
    "\n",
    "#set the projection of these new shapes to the same as is used for our Indonesia shape\n",
    "projection(merged_polys) <- projection(world_Indonesia)\n",
    "\n",
    "cat(\"\\nSubdivision rectangle creation time\",\"\\n\"); proc.time() - time1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the newly created cells to check that they look correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot(merged_polys, col='red', axes=TRUE)\n",
    "plot(world_Indonesia, col=rgb(1,1,1,0.5), add=TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intersected result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Intersected chunks with country shape\n",
    "chunks_Ind <- intersect(world_Indonesia, merged_polys)\n",
    "plot(chunks_Ind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many cells overlapped with Indonesia?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "length(chunks_Ind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract values from Indonesia chunks - Serial version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shapecount <- length(chunks_Ind) # total number of chunks\n",
    "\n",
    "endcount <- 10 # choose a number less than shapecount for testing\n",
    "mat <- vector(\"list\", endcount)\n",
    "\n",
    "extractor <- function(p){\n",
    "    clip1_Ind <- crop(IndRasters, extent(chunks_Ind[p,])) #crop to extent of polygon\n",
    "    clip2_Ind <- rasterize(chunks_Ind[p,], clip1_Ind, mask=TRUE)\n",
    "    ext <- getValues(clip2_Ind) #much faster than raster::extract\n",
    "    print(ext)\n",
    "    tab<-table(ext) #tabulates the values of the raster in the polygon\n",
    "    print(tab)\n",
    "}\n",
    "\n",
    "starttimeInd <- proc.time() #begin time\n",
    "\n",
    "#apply (run) the extractor function for each chunk of Indonesia, up to the endcount limit\n",
    "tablesInd <- lapply(1:endcount, function(p) extractor(p)) \n",
    "    \n",
    "dfInd <- do.call(cbind, tablesInd) #call the cbind (combine by columns) function on each table in the `tablesInd` list\n",
    "endtimeInd <- proc.time() #end time\n",
    "\n",
    "cat(\"Time to extract values from \", endcount, \" polygons:\\n\")\n",
    "print(summary(endtimeInd - starttimeInd))\n",
    "\n",
    "cat(\"\\nEstimated total time for serial extraction of all Indonesia values:\\n\")\n",
    "cat((endtimeInd - starttimeInd)[[3]] * length(chunks_Ind) / endcount / 60, \" minutes\")\n",
    "\n",
    "#dfInd is a data frame with a column for every table from the tablesInd list.\n",
    "# Sum across each row to get the frequency of each raster value\n",
    "sumInd <- as.data.frame(rowSums(dfInd)) \n",
    "colnames(sumInd) <- \"Freq\" #assign the name Freq to the column in the data frame to be consistent with Guinea Bissau method\n",
    "sumInd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract values from Indonesia chunks - Parallel version\n",
    "As above, but using `foreach` instead of `lapply`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shapecount <- length(chunks_Ind) # total number of chunks\n",
    "\n",
    "endcount <- 10 # use the same number as the above serial version to measure speedup\n",
    "              # SET TO SHAPECOUNT to extract data for all of Indonesia\n",
    "extractor <- function(p){1\n",
    "    clip1_Ind <- crop(IndRasters, extent(chunks_Ind[p,])) #crop to extent of polygon\n",
    "    clip2_Ind <- rasterize(chunks_Ind[p,], clip1_Ind, mask=TRUE)\n",
    "    ext <- getValues(clip2_Ind) #much faster than raster::extract\n",
    "    tab<-table(ext) #tabulates the values of the raster in the polygon\n",
    "}\n",
    "\n",
    "\n",
    "cluster = makeCluster(10, type = \"SOCK\")\n",
    "registerDoSNOW(cluster)\n",
    "clusterExport(cluster, c(\"IndRasters\",\"chunks_Ind\", \"extractor\"))\n",
    "ptm <- proc.time()    \n",
    "results = foreach(n = 1:endcount, .combine = cbind) %dopar% {\n",
    "     library(raster); \n",
    "     #Define function\n",
    "     extractor(n)\n",
    "}\n",
    "#results\n",
    "proc.time() - ptm \n",
    "stopCluster(cluster)\n",
    "\n",
    " \n",
    "sumInd <- as.data.frame(rowSums(results))\n",
    "colnames(sumInd) <- \"Freq\"\n",
    "sumInd\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1: How much did a parallel code speed up a sequential code?\n",
    "Sp = Ts / Tp\n",
    "- p = # of processors\n",
    "- Ts = execution time of the sequential code\n",
    "- Tp = execution time of the parallel code with p processors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R 3.2",
   "language": "R",
   "name": "ir32"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.2.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
